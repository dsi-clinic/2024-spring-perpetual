{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCLP Demonstration\n",
    "\n",
    "Authors: Kaiwen Dong\n",
    "\n",
    "The purpose of this notebook is to demonstrate the functionality of the Maximal Covering Location Problem (MCLP) to identify optimal bin placement locations. Hilo, Hawaii is used as a case study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "import geopandas as gpd\n",
    "import spaghetti\n",
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Application imports\n",
    "from utils.constants import DATA_DIR\n",
    "from utils.mclp import (\n",
    "    load_and_clean_data,\n",
    "    summarize_clusters,\n",
    "    cluster_foot_traffic,\n",
    "    clean_coordinates,\n",
    "    calculate_weights_and_cost_matrix,\n",
    "    setup_and_solve_mclp,\n",
    "    print_coverage_results,\n",
    "    create_network_with_lattice,\n",
    "    snap_observations_to_network,\n",
    "    generate_mapbox_cost_matrix,\n",
    "    visualize_results,\n",
    "    perform_parameter_sweep_on_service_radius,\n",
    "    visualize_folium_results,\n",
    ")\n",
    "\n",
    "# Suppress warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "CLIENT_COUNT = 200\n",
    "FACILITY_COUNT = 125\n",
    "SERVICE_RADIUS = 30\n",
    "P_FACILITIES = 10\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "ENV_PATH = Path(__file__).resolve().parents[3] / \".env\"\n",
    "load_dotenv(dotenv_path=ENV_PATH)\n",
    "\n",
    "# Access the Mapbox API token\n",
    "MAPBOX_ACCESS_TOKEN = os.getenv(\"MAPBOX_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean Data\n",
    "# We load and clean the datasets for the analysis. This includes the API data, foot traffic data, and apartment data.\n",
    "# The data is then cleaned to remove duplicates and ensure consistency.\n",
    "hilo_all_gdf, foot, large_apartments_NJ = load_and_clean_data(\n",
    "    api_data_path=f\"{DATA_DIR}/hilo_api_data.json\",\n",
    "    foot_traffic_path=f\"{DATA_DIR}/foot_traffic.parquet\",\n",
    "    large_apartments_path=f\"{DATA_DIR}/large_apartments.geojson\",\n",
    "    small_apartments_path=f\"{DATA_DIR}/small_apartments.geojson\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform K-means clustering on the foot traffic data to identify clusters of high-demand areas.\n",
    "# The clusters are then summarized to calculate the total visit counts for each cluster, which are used as weights in the MCLP analysis.\n",
    "foot_traffic_gdf = gpd.GeoDataFrame(\n",
    "    foot, geometry=gpd.points_from_xy(foot.longitude, foot.latitude)\n",
    ")\n",
    "foot_traffic_gdf.set_crs(large_apartments_NJ.crs, inplace=True)\n",
    "foot_traffic_gdf = cluster_foot_traffic(foot_traffic_gdf)\n",
    "\n",
    "# Summarize clusters\n",
    "cluster_summary = summarize_clusters(foot_traffic_gdf)\n",
    "cluster_summary[\"weights\"] = cluster_summary[\"total_visit_counts\"] / 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We clean the coordinates of the client points and facility points to ensure all geometries are valid and finite.\n",
    "client_points = clean_coordinates(cluster_summary[[\"geometry\", \"weights\"]])\n",
    "facility_points = clean_coordinates(large_apartments_NJ)[[\"geometry\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve MCLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the cost matrix and weights for the client and facility points.\n",
    "# Using these, we set up and solve the Maximal Covering Location Problem (MCLP)\n",
    "# to identify the optimal placement of facilities to maximize coverage.\n",
    "# The results are then printed to show the coverage achieved by the selected facilities.\n",
    "weights, cost_matrix = calculate_weights_and_cost_matrix(\n",
    "    client_points, facility_points, SERVICE_RADIUS\n",
    ")\n",
    "\n",
    "# Solve MCLP\n",
    "mclp_result = setup_and_solve_mclp(\n",
    "    cost_matrix, weights, SERVICE_RADIUS, P_FACILITIES\n",
    ")\n",
    "print_coverage_results(mclp_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate lattice extent and create network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Network with Lattice and Snap Observations\n",
    "# We create a network with a regular lattice based on the extent of the client points.\n",
    "# The client and facility points are then snapped to this network for visualization and further analysis.\n",
    "minx, miny, maxx, maxy = calculate_lattice_extent(client_points)\n",
    "ntw = create_network_with_lattice(minx, miny, maxx, maxy)\n",
    "\n",
    "# Snap observations to network\n",
    "clients_snapped, facilities_snapped = snap_observations_to_network(\n",
    "    ntw, client_points, facility_points\n",
    ")\n",
    "\n",
    "# Visualize results\n",
    "streets = spaghetti.element_as_gdf(ntw, arcs=True)\n",
    "visualize_results(clients_snapped, facilities_snapped, streets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate MapBox Cost Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate the cost matrix using the Mapbox API. This allows for a more accurate representation of travel distances between points.\n",
    "cost_matrix = generate_mapbox_cost_matrix(\n",
    "    clients_snapped,\n",
    "    facilities_snapped,\n",
    "    mapbox_access_token=MAPBOX_ACCESS_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Grid Search on Service Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform a grid search on the service radius to find the best coverage.\n",
    "# This helps to identify the optimal service radius for the MCLP analysis.\n",
    "coverage_results = perform_parameter_sweep_on_service_radius(\n",
    "    cost_matrix, weights, P_FACILITIES\n",
    ")\n",
    "\n",
    "# Print the coverage rates for each service radius\n",
    "for service_radius, coverage in coverage_results:\n",
    "    print(f\"Service Radius: {service_radius} units, Coverage: {coverage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find and Visualize the Best Result on a Folium Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We find the best result from the grid search and visualize it on an interactive Folium map.\n",
    "# This provides a clear and interactive way to understand the optimal bin placement locations.\n",
    "best_service_radius, best_coverage = max(coverage_results, key=lambda x: x[1])\n",
    "\n",
    "mclp_result = setup_and_solve_mclp(\n",
    "    cost_matrix, weights, best_service_radius, P_FACILITIES\n",
    ")\n",
    "demand_coords = [(point.x, point.y) for point in clients_snapped.geometry]\n",
    "facility_coords = [(point.x, point.y) for point in facilities_snapped.geometry]\n",
    "visualize_folium_results(\n",
    "    demand_coords,\n",
    "    weights,\n",
    "    facility_coords,\n",
    "    mclp_result,\n",
    "    \"Hilo_All_apartments.html\",\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Best Service Radius: {best_service_radius} units, Coverage:\"\n",
    "    f\" {best_coverage}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "- The Maximal Covering Location Problem (MCLP) was effectively used to identify optimal bin placement locations in Hilo, Hawaii.\n",
    "- Clustering of foot traffic data helped in identifying high-demand areas and assigning appropriate weights.\n",
    "- The combination of local and Mapbox API cost matrices allowed for flexible and scalable analysis.\n",
    "- The results provide actionable insights for improving recycling bin placement strategies to maximize coverage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
