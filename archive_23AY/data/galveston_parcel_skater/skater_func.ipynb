{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c4eccce",
   "metadata": {},
   "source": [
    "#### This jupyter notebook is revised from https://pysal.org/spopt/notebooks/skater.html. You can check the explanation in this link for details\n",
    "#### Warning: Run this file in your local computer will take extremely long time. Run this in a high-speed computing server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7093fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import libpysal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas\n",
    "import shapely\n",
    "from sklearn.metrics import pairwise as skm\n",
    "import spopt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is revised based on the process in the skater link above. \n",
    "# The whole process is: 1. load the shapefile 2. use the weight column in the shapefile (weight is determined in the K-mean collecion point notebook)\n",
    "# 3. Set the parameters of the algorithm (e.g. n_clusters) 4. Run the skater model and assign the label to the shapefile\n",
    "def get_skater_output(dataset, num_of_cluster, column_name):\n",
    "    '''\n",
    "    Perform skater with givin dataset and number of cluster\n",
    "    \n",
    "    Arg:\n",
    "        dataset (shp or GeoJSON): the dataset we want to cluster\n",
    "        num_of_cluster (int): number of cluster we want\n",
    "        column_name (str): the column name we want to use as weight\n",
    "    '''\n",
    "    parcel = geopandas.read_file(dataset)\n",
    "    # The column I use as weight\n",
    "    attrs_name = [column_name]\n",
    "    w = libpysal.weights.Queen.from_dataframe(parcel)\n",
    "    # Number of clusters. Warning: n_clusters here won't be the exact number of clusters we got. We will got\n",
    "    # more clusters than this number\n",
    "    n_clusters = num_of_cluster\n",
    "    trace = False\n",
    "    islands = \"increase\"\n",
    "    spanning_forest_kwds = dict(\n",
    "        dissimilarity=skm.manhattan_distances,\n",
    "        affinity=None,\n",
    "        reduction=numpy.sum,\n",
    "        center=numpy.mean,\n",
    "        verbose=2\n",
    "    )\n",
    "    model = spopt.region.Skater(\n",
    "    parcel,\n",
    "    w,\n",
    "    attrs_name,\n",
    "    n_clusters=n_clusters,\n",
    "    trace=trace,\n",
    "    spanning_forest_kwds=spanning_forest_kwds\n",
    "    )\n",
    "    model.solve()\n",
    "    # Assign the label\n",
    "    parcel[\"label\"] = model.labels_\n",
    "    # Produce the shapefile as the output\n",
    "    parcel.to_file(\"result.shp\")\n",
    "    return parcel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7fe562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the new shapefile that each parcel belongs to a cluster generated by Skater\n",
    "# The shapefile I used here, generated from the k-mean collection point jupyter notebook (will explain in that notebook),\n",
    "# is in the galveston_shapefile_parcel folder\n",
    "get_skater_output(\"galveston_parcel_skater.shp\", 125, \"weight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
